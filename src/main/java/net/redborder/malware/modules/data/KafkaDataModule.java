package net.redborder.malware.modules.data;

import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.ObjectMapper;
import kafka.consumer.Consumer;
import kafka.consumer.ConsumerConfig;
import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.javaapi.consumer.ConsumerConnector;
import net.redborder.malware.config.Config;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.util.*;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class KafkaDataModule extends AbstractDataModule{

    private static final Logger log = LoggerFactory.getLogger(KafkaDataModule.class);

    private ConsumerConnector consumerConnector;

    private LinkedList<Map<String, Object>> incrementalList;

    private int lastIndex = 0;

    private ExecutorService consumerThread;

    public KafkaDataModule(Config conf){
        super(conf);
    }

    @Override
    public Object getFullDataImpl() {
        result = new ArrayList<Map<String, Object>>();
        return result;
    }

    @Override
    public Object getIncrementalImpl() {

        lastIndex = incrementalList.size();
        ArrayList<Map<String, Object>> currentIncremental = (ArrayList<Map<String, Object>>) incrementalList.clone();

        incrementalList.subList(0, lastIndex).clear();

        result = currentIncremental.clone();

        return result;
    }

    @Override
    public Object doQueryImpl() {
        result = new ArrayList<Map<String, Object>>();
        return result;
    }

    @Override
    public void prepareQueryImpl(Object parameter) {
    // nothing
    }

    @Override
    public void initImpl() {

        log.info("Init Kafka data module");

        incrementalList = new LinkedList<>();
        Properties props = (Properties)config.getProperties().clone();
        props.put("group.id",UUID.randomUUID().toString());

        consumerConnector = Consumer.createJavaConsumerConnector(new ConsumerConfig(props));

        Map<String, Integer> topicCountMap = new HashMap<>();
        topicCountMap.put("rb_malware", 1);

        Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumerConnector.createMessageStreams(topicCountMap);
        List<KafkaStream<byte[], byte[]>> streams = consumerMap.get("rb_malware");

        consumerThread = Executors.newSingleThreadExecutor();
        consumerThread.submit(new ConsumerFromTopic(streams.get(0)));

    }

    @Override
    public void shutdownImpl() {
        log.info("Shutdown Kafka data module ...");
        consumerConnector.shutdown();
        consumerThread.shutdown();
        log.info("Done!");
    }

    @Override
    public String getDataModuleName() {
        return "Kafka";
    }

    private class ConsumerFromTopic implements Runnable{

        private KafkaStream a_stream;
        private ObjectMapper _mapper;

        public ConsumerFromTopic(KafkaStream m_stream){
            this.a_stream = m_stream;
            _mapper = new ObjectMapper();
        }

        @Override
        public void run() {
            ConsumerIterator<byte[], byte[]> it = a_stream.iterator();

            while(it.hasNext()) {
                try {

                    Map<String, Object> mapJson = _mapper.readValue(it.next().message(), new TypeReference<HashMap<String, Object>>() {
                    });

                    mapJson.remove("cuckoo_before");
                    mapJson.put("action", "create");

                    incrementalList.push(mapJson);

                } catch (IOException e) {
                    e.printStackTrace();
                }

            }
        }

    }
}
